{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "c106a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "\n",
    "# Set options\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "3ff3b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, sort on zip and date and set index to datetime\n",
    "with open(\"../data/sfr_mfr_mig_pre-processed.pkl\", \"rb\") as f: df = pickle.load(f)\n",
    "df.sort_values(['census_cbsa_geoid', 'census_zcta5_geoid', 'date'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e033ab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'census_cbsa_geoid', 'census_zcta5_geoid', 'sfr_rental_index',\n",
       "       'sfr_price_index', 'coef', 'nounits', 'occupied_units', 'mfr_occ',\n",
       "       'mfr_mean_occ_index', 'mfr_mean_rent', 'mfr_mean_rent_index', 'month',\n",
       "       'cos_month', 'sin_month', 'sfr_rental_delta', 'sfr_price_delta',\n",
       "       'mfr_occ_delta', 'mfr_rental_delta', 'us_zip', 'population',\n",
       "       'student_population_fraction', 'netflow_estimated', 'inflow_estimated',\n",
       "       'outflow_estimated', 'cumulative_netflow_estimated',\n",
       "       'median_income_inflow', 'median_income', 'median_income_difference',\n",
       "       'median_age_inflow', 'median_age', 'median_age_difference',\n",
       "       'inflow_index', 'outflow_index', 'netflow_index', 'income_inflow_index',\n",
       "       'income_diff_index', 'age_inflow_index', 'age_inflow_diff_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a4f092fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for time frame that includes MFR data (Jan 2015 - June 2023)\n",
    "df = df.loc[(df.date >= '2015-01-01') & (df.date <= '2023-06-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "47deafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop incomplete zips\n",
    "drops = df.loc[df.mfr_occ.isna()].census_zcta5_geoid.unique().tolist()\n",
    "df.drop(df.loc[df['census_zcta5_geoid'].isin(drops)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "87d210aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>census_zcta5_geoid</th>\n",
       "      <th>sfr_rental_delta</th>\n",
       "      <th>sfr_price_delta</th>\n",
       "      <th>mfr_rental_delta</th>\n",
       "      <th>mfr_occ_delta</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>sin_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>30002</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>-0.3415</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>30002</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>-0.1288</td>\n",
       "      <td>1.5483</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>30002</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>-2.1542</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>30002</td>\n",
       "      <td>0.4872</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>-0.3801</td>\n",
       "      <td>-0.5663</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>30002</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-1.5642</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.8660</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36073</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>44333</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>-1.3466</td>\n",
       "      <td>1.3648</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36074</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>44333</td>\n",
       "      <td>0.6817</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>-0.2888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36075</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>44333</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>0.3216</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36076</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>44333</td>\n",
       "      <td>1.3360</td>\n",
       "      <td>1.8028</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>-0.2865</td>\n",
       "      <td>-0.8660</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36077</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>44333</td>\n",
       "      <td>-0.1459</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>-1.3709</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18462 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date census_zcta5_geoid  sfr_rental_delta  sfr_price_delta  \\\n",
       "60    2015-01-01              30002            0.0852          -0.3415   \n",
       "61    2015-02-01              30002            0.4399          -0.1288   \n",
       "62    2015-03-01              30002            0.5385           0.2211   \n",
       "63    2015-04-01              30002            0.4872           0.6915   \n",
       "64    2015-05-01              30002            0.8189           1.0205   \n",
       "...          ...                ...               ...              ...   \n",
       "36073 2023-02-01              44333            0.8291          -1.3466   \n",
       "36074 2023-03-01              44333            0.6817           0.1833   \n",
       "36075 2023-04-01              44333            0.9218           1.0300   \n",
       "36076 2023-05-01              44333            1.3360           1.8028   \n",
       "36077 2023-06-01              44333           -0.1459           0.8675   \n",
       "\n",
       "       mfr_rental_delta  mfr_occ_delta  cos_month  sin_month  \n",
       "60               0.0000         0.0000     0.8660     0.5000  \n",
       "61               1.5483         0.0000     0.5000     0.8660  \n",
       "62              -2.1542         0.2427     0.0000     1.0000  \n",
       "63              -0.3801        -0.5663    -0.5000     0.8660  \n",
       "64              -1.5642         0.0000    -0.8660     0.5000  \n",
       "...                 ...            ...        ...        ...  \n",
       "36073            1.3648         0.0000     0.5000     0.8660  \n",
       "36074            0.7726        -0.2888     0.0000     1.0000  \n",
       "36075            0.3216         0.0000    -0.5000     0.8660  \n",
       "36076            0.0209        -0.2865    -0.8660     0.5000  \n",
       "36077           -1.3709         0.0000    -1.0000     0.0000  \n",
       "\n",
       "[18462 rows x 8 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only desired columns\n",
    "df = df[['date', 'census_zcta5_geoid', 'sfr_rental_delta', 'sfr_price_delta', \n",
    "         'mfr_rental_delta', 'mfr_occ_delta', 'cos_month', 'sin_month']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "32eae2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5]\n",
      "[6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "array = [3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "print(array[0:3])\n",
    "print(array[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "868c30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class\n",
    "\n",
    "class SFR_DATASET(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = df.to_dict('records') # random access is easier with dictionaries\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.data) - 18  # subtract length of input + output\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        \n",
    "        input = pd.DataFrame(self.data[idx:idx+12])\n",
    "        output = pd.DataFrame(self.data[idx+12:idx+18])\n",
    "        \n",
    "        # each of these are 12x1 tensors (12 months of data)\n",
    "        in_sfr = torch.tensor(input['sfr_rental_delta']) \n",
    "        in_sfp = torch.tensor(input['sfr_price_delta'])\n",
    "        in_mfr = torch.tensor(input['mfr_rental_delta'])\n",
    "        in_mfo = torch.tensor(input['mfr_occ_delta'])\n",
    "        in_sinm = torch.tensor(input['sin_month'])\n",
    "        in_cosm = torch.tensor(input['cos_month']) \n",
    "        x = torch.cat((in_sfr, in_sfp, in_mfr, in_mfo, in_sinm, in_cosm), dim = 0) # concat into 72-wide vector\n",
    "        y = torch.tensor(output['sfr_rental_delta'])\n",
    "        return {'X':x.float(), 'Y':y.float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "58122065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "col_transform = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", MinMaxScaler(feature_range=(-1, 1)), make_column_selector(dtype_include=np.number))], \n",
    "        remainder='passthrough',\n",
    "        verbose_feature_names_out = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "c6b37b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip dict to store class for each zip\n",
    "zip_dict_train = {}\n",
    "zip_dict_test = {}\n",
    "\n",
    "# Cast the class, separating out by zipcdoe\n",
    "for zipcode in df['census_zcta5_geoid'].unique():\n",
    "    \n",
    "    # Filter for single zipcode\n",
    "    zipcode_df = df[df['census_zcta5_geoid'] == zipcode]\n",
    "    \n",
    "    # Train test split\n",
    "    df_train = zipcode_df.loc[(df.date < '2022-01-01')]\n",
    "    df_test = zipcode_df.loc[(df.date >= '2022-01-01')]\n",
    "    \n",
    "    # Transform training data, cast class and store\n",
    "    train_X = col_transform.fit_transform(df_train)\n",
    "    train_X = pd.DataFrame(train_X, columns = col_transform.get_feature_names_out())\n",
    "    train_sfr = SFR_DATASET(train_X)\n",
    "    zip_dict_train[zipcode] = train_sfr\n",
    "    \n",
    "    # Transform testing data, cast class and store\n",
    "    test_X = col_transform.fit_transform(df_test)\n",
    "    test_X = pd.DataFrame(test_X, columns = col_transform.get_feature_names_out())\n",
    "    test_sfr = SFR_DATASET(test_X)\n",
    "    zip_dict_test[zipcode] = test_sfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9a580d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "{'X': tensor([-1.0000e+00, -7.3362e-01, -6.5953e-01, -6.9805e-01, -4.4901e-01,\n",
      "        -5.4270e-01, -4.3483e-01, -7.6435e-01, -7.1402e-01, -7.9240e-01,\n",
      "        -9.2652e-01, -9.0846e-01, -8.0106e-01, -6.4592e-01, -3.9060e-01,\n",
      "        -4.7322e-02,  1.9270e-01, -4.9943e-01,  5.4419e-01,  8.4357e-01,\n",
      "         8.7634e-02, -2.1854e-01, -5.0432e-01, -2.8387e-01, -2.6338e-01,\n",
      "        -9.6415e-02, -4.9568e-01, -3.0436e-01, -4.3206e-01, -3.9460e-01,\n",
      "        -5.0374e-01,  1.2117e-01, -2.1214e-01, -1.9494e-01, -7.2910e-02,\n",
      "        -1.2560e-02,  1.2108e-01,  1.2108e-01,  2.9970e-01, -2.9572e-01,\n",
      "         1.2108e-01,  3.5924e-01, -1.1709e-01,  3.6798e-01,  6.5695e-01,\n",
      "         2.4016e-01,  1.2108e-01,  2.9970e-01,  5.0000e-01,  8.6603e-01,\n",
      "         1.0000e+00,  8.6603e-01,  5.0000e-01,  1.2246e-16, -5.0000e-01,\n",
      "        -8.6603e-01, -1.0000e+00, -8.6603e-01, -5.0000e-01, -2.4493e-16,\n",
      "         8.6603e-01,  5.0000e-01,  6.1232e-17, -5.0000e-01, -8.6603e-01,\n",
      "        -1.0000e+00, -8.6603e-01, -5.0000e-01, -1.8370e-16,  5.0000e-01,\n",
      "         8.6603e-01,  1.0000e+00]), 'Y': tensor([-0.7941, -0.5946, -0.5692, -0.4795, -0.5433, -0.5015])}\n"
     ]
    }
   ],
   "source": [
    "# check contents of dict\n",
    "print(len(zip_dict_train['30002']))\n",
    "print(zip_dict_train['30002'][0])\n",
    "\n",
    "# for given index\n",
    "# returns X as 1x18 vector (3 months for each of the 6 input variables)\n",
    "# returns y as 1x6 vecotr (6 month prediction for sfr_rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "eeeb7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: simple multilayer perceptron\n",
    "# sequential 3 layer model with 1 hidden dim\n",
    "\n",
    "class SFR_MODEL(nn.Module):\n",
    "    def __init__(self, indim, hdim, outdim):\n",
    "        super().__init__() # for nn.MOdule you must initialize the super class\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(indim, hdim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hdim, outdim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "1ba1a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFR_MODEL(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=72, out_features=39, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=39, out_features=6, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create instance of model\n",
    "\n",
    "# indim matches length of input vector\n",
    "# outdim matches length of output vector\n",
    "# hdim?\n",
    "\n",
    "model = SFR_MODEL(indim = 72, hdim = 39, outdim = 6)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "4ac14dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training loop\n",
    "# optimizer - Adam good to start with\n",
    "# datalaoder - wrap around dataset to shuffle through batches\n",
    "\n",
    "opt = Adam(model.parameters())\n",
    "batchsize = 3\n",
    "epochs = 150 # go though data 3x\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "cc4a0da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 150/150 [00:24<00:00,  6.21it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.76it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:27<00:00,  5.51it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.77it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.76it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:34<00:00,  4.29it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.74it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.71it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:35<00:00,  4.26it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.96it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.85it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:47<00:00,  3.16it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:35<00:00,  4.22it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.90it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:27<00:00,  5.38it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.84it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.72it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.82it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:28<00:00,  5.34it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [02:44<00:00,  1.10s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.14it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:33<00:00,  4.47it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:32<00:00,  4.62it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:33<00:00,  4.43it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.72it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.78it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:28<00:00,  5.35it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.80it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.88it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.87it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:37<00:00,  1.53it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.83it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.64it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.85it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:28<00:00,  5.31it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:38<00:00,  3.86it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.08it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:28<00:00,  5.29it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.85it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.80it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:32<00:00,  4.59it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:36<00:00,  4.15it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.75it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:40<00:00,  3.66it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:39<00:00,  3.77it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:43<00:00,  3.47it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:35<00:00,  4.17it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:37<00:00,  4.01it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:41<00:00,  3.57it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:33<00:00,  4.42it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:35<00:00,  4.21it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:45<00:00,  3.32it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:39<00:00,  3.82it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:33<00:00,  4.54it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:30<00:00,  4.90it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:36<00:00,  4.08it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:38<00:00,  3.86it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:34<00:00,  4.38it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.79it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:00<00:00,  2.47it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.56it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.66it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.93it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.14it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:52<00:00,  2.86it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.83it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  6.00it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:27<00:00,  5.46it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  6.00it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:01<00:00,  2.43it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.83it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:43<00:00,  3.49it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:31<00:00,  4.80it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:27<00:00,  5.41it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.57it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.84it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.66it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:25<00:00,  5.77it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:26<00:00,  5.72it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [02:13<00:00,  1.13it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [18:35<00:00,  7.44s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:28<00:00,  5.19it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.01it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [03:30<00:00,  1.41s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:11<00:00,  2.10it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:00<00:00,  2.47it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:09<00:00,  2.15it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:49<00:00,  3.04it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:47<00:00,  3.17it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:02<00:00,  2.41it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:59<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 150/150 [01:01<00:00,  2.44it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:53<00:00,  2.83it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:55<00:00,  2.69it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:49<00:00,  3.02it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:44<00:00,  3.37it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:45<00:00,  3.33it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.93it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:48<00:00,  3.09it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:59<00:00,  2.51it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:54<00:00,  2.76it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:15<00:00,  1.99it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:01<00:00,  2.43it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:57<00:00,  2.63it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:01<00:00,  2.44it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.93it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:50<00:00,  2.98it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.91it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:55<00:00,  2.70it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:53<00:00,  2.81it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:54<00:00,  2.73it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:56<00:00,  2.67it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.91it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:48<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:47<00:00,  3.13it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:49<00:00,  3.02it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:44<00:00,  3.37it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:45<00:00,  3.26it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:44<00:00,  3.36it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:57<00:00,  2.62it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.89it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:03<00:00,  2.38it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:03<00:00,  2.35it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:09<00:00,  2.14it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:59<00:00,  2.53it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:57<00:00,  2.61it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:55<00:00,  2.73it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:50<00:00,  3.00it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.90it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:52<00:00,  2.88it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.93it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:50<00:00,  2.95it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:49<00:00,  3.02it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:48<00:00,  3.10it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:53<00:00,  2.81it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:53<00:00,  2.82it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:24<00:00,  1.77it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:22<00:00,  1.83it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:50<00:00,  2.96it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:52<00:00,  2.85it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:56<00:00,  2.63it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:57<00:00,  2.61it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:51<00:00,  2.92it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:46<00:00,  3.21it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:50<00:00,  2.98it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:54<00:00,  2.74it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:10<00:00,  2.14it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:58<00:00,  2.55it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:06<00:00,  2.26it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:54<00:00,  2.75it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.02it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.14it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.14it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.03it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [15:32<00:00,  6.21s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [03:24<00:00,  1.36s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [07:43<00:00,  3.09s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [18:19<00:00,  7.33s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [07:56<00:00,  3.18s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [03:46<00:00,  1.51s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [01:44<00:00,  1.43it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [03:55<00:00,  1.57s/it]\n",
      "100%|████████████████████████████████████████████████| 150/150 [2:10:03<00:00, 52.03s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [03:57<00:00,  1.58s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [06:54<00:00,  2.76s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [07:13<00:00,  2.89s/it]\n",
      "100%|████████████████████████████████████████████████| 150/150 [1:13:42<00:00, 29.49s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [02:59<00:00,  1.20s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [09:03<00:00,  3.62s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [51:49<00:00, 20.73s/it]\n",
      "100%|██████████████████████████████████████████████| 150/150 [10:43:54<00:00, 257.56s/it]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:38<00:00,  3.90it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:29<00:00,  5.12it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:27<00:00,  5.42it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:17<00:00,  8.58it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:19<00:00,  7.76it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:18<00:00,  8.28it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:20<00:00,  7.46it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:24<00:00,  6.10it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:18<00:00,  8.18it/s]\n",
      "100%|██████████████████████████████████████████████████| 150/150 [00:20<00:00,  7.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "losses_dict = {} # initialize dict to store loss values for each zip\n",
    "\n",
    "for zipcode in df['census_zcta5_geoid'].unique():\n",
    "    \n",
    "    # Access one zipcdode\n",
    "    sfr = zip_dict_train[zipcode]\n",
    "    \n",
    "    # create dataloader\n",
    "    dl = DataLoader(sfr, batch_size = batchsize, shuffle = True, drop_last = True)\n",
    "    \n",
    "    # initialize list for zip-level losses\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in trange(epochs):\n",
    "        for batch in dl:\n",
    "            \n",
    "            opt.zero_grad() # at the beginning of batch, zero out the optimizer\n",
    "        \n",
    "            # use inputs and outputs to make model prediction\n",
    "            x = batch['X']\n",
    "            y = batch['Y']\n",
    "            y_hat = model(x)\n",
    "        \n",
    "            loss = loss_fn(y_hat, y) # calculate loss\n",
    "            loss.backward() # calculate gradient of loss\n",
    "            opt.step() # runs the optimizer and updates model params based on gradient\n",
    "            losses.append(loss.cpu().detach().numpy()) # single value as a numpy\n",
    "            \n",
    "    losses_dict[zipcode] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3903c89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff220dc3580>]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot decreasing loss for one zip\n",
    "plt.plot(np.array(losses_dict['30002']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c276b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970ecb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a031c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is all a work in progress and copied code...nothing running yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model\n",
    "\n",
    "training_losses_dict = {} # initialize dict to store loss values for each zip\n",
    "\n",
    "for zipcode in df['census_zcta5_geoid'].unique():\n",
    "    \n",
    "    # Access one zipcdode\n",
    "    sfr = zip_dict_train[zipcode]\n",
    "    \n",
    "    # create dataloader\n",
    "    dl = DataLoader(sfr, batch_size = batchsize, shuffle = True, drop_last = True)\n",
    "    \n",
    "    # initialize list for zip-level training losses\n",
    "    losses = []\n",
    "    \n",
    "    # training loop\n",
    "    \n",
    "    for epoch in trange(epochs):\n",
    "        for batch in dl:\n",
    "            \n",
    "            opt.zero_grad() # at the beginning of batch, zero out the optimizer\n",
    "        \n",
    "            # use inputs and outputs to make model prediction\n",
    "            x = batch['X']\n",
    "            y = batch['Y']\n",
    "            y_hat = model(x)\n",
    "        \n",
    "            loss = loss_fn(y_hat, y) # calculate loss\n",
    "            loss.backward() # calculate gradient of loss\n",
    "            opt.step() # runs the optimizer and updates model params based on gradient\n",
    "            losses.append(loss.cpu().detach().numpy()) # single value as a numpy\n",
    "         \n",
    "    training_losses_dict[zipcode] = losses\n",
    "\n",
    "    # Test loop\n",
    "    \n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for example in xor_dataset:\n",
    "            x = example['x']\n",
    "            y = example['y']\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            print('x:', x, 'y:', y, 'y_hat:', y_hat, 'loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866631f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns = ['zip', 'model', 'mape', 'mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    output_zip = []\n",
    "    output_zip.append(zipcode)\n",
    "    output_zip.append('nn_batch3_epoch150')\n",
    "    output_zip.append(performance_metrics(df_cv)['mape'].mean())\n",
    "    output_zip.append(performance_metrics(df_cv)['mae'].mean())\n",
    "    output_zip.append(performance_metrics(df_cv)['mse'].mean())\n",
    "    output.loc[len(output)] = output_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Cole's example code\n",
    "model = model.cpu()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in xor_dataset:\n",
    "        x = example['x']\n",
    "        y = example['y']\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        print('x:', x, 'y:', y, 'y_hat:', y_hat, 'loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b275328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://theaveragecoder.medium.com/training-and-testing-a-basic-neural-network-using-pytorch-4010300fda45\n",
    "\n",
    "test_loss = 0.0\n",
    "correct, total = 0,0\n",
    "\n",
    "for data,label in testloader:\n",
    "    if is_gpu:\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "    output = model(data)\n",
    "    for o,l in zip(torch.argmax(output,axis = 1),label):\n",
    "        if o == l:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    loss = criterion(output,label)\n",
    "    test_loss += loss.item() * data.size(0)\n",
    "print(f'Testing Loss:{test_loss/len(testloader)}')\n",
    "print(f'Correct Predictions: {correct}/{total}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
